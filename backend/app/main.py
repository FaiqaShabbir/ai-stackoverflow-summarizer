import os
from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from dotenv import load_dotenv
import logging

from .models import (
    SummarizeRequest, 
    ChatRequest, 
    APIResponse, 
    ChatAPIResponse,
    SummaryData
)
from .services.openai_service import OpenAIService
from .services.anthropic_service import AnthropicService
from .utils.url_parser import validate_input, clean_url

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize FastAPI app
app = FastAPI(
    title="AI StackOverflow Summarizer API",
    description="API for summarizing StackOverflow questions using AI",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Configure CORS
origins = os.getenv("CORS_ORIGINS", "http://localhost:3000").split(",")
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialize services
try:
    openai_service = OpenAIService()
    anthropic_service = AnthropicService()
except Exception as e:
    logger.error(f"Failed to initialize services: {e}")
    openai_service = None
    anthropic_service = None


@app.get("/")
async def root():
    """Health check endpoint"""
    return {
        "message": "AI StackOverflow Summarizer API",
        "version": "1.0.0",
        "status": "running"
    }


@app.get("/health")
async def health_check():
    """Detailed health check"""
    services_status = {
        "openai": openai_service is not None,
        "anthropic": anthropic_service is not None
    }
    
    return {
        "status": "healthy" if all(services_status.values()) else "degraded",
        "services": services_status
    }


@app.post("/api/summarize", response_model=APIResponse)
async def summarize_question(request: SummarizeRequest):
    """
    Summarize a StackOverflow question or technical text
    """
    try:
        # Validate input
        is_valid, error_message = validate_input(
            url=str(request.url) if request.url else None,
            question=request.question
        )
        
        if not is_valid:
            return APIResponse(
                success=False,
                error=error_message
            )
        
        # Initialize content variables
        title = ""
        content = ""
        tags = []
        source_url = None
        
        if request.url:
            # Handle URL input
            url = clean_url(str(request.url))
            source_url = url
            
            # Extract content from StackOverflow
            if anthropic_service:
                extraction_result = await anthropic_service.extract_stackoverflow_content(url)
                
                if extraction_result["success"]:
                    title = extraction_result["title"]
                    content = extraction_result["content"]
                    tags = extraction_result.get("tags", [])
                else:
                    # Fallback to OpenAI if Anthropic fails
                    if openai_service:
                        fallback_prompt = f"Summarize the StackOverflow question at this URL: {url}. If you know about this question, provide a summary. If not, say so."
                        try:
                            summary_data = await openai_service.summarize_content("StackOverflow Question", fallback_prompt, [])
                            summary_data.source_url = url
                            return APIResponse(
                                success=True,
                                data=summary_data,
                                message="Summary generated by OpenAI fallback."
                            )
                        except Exception:
                            pass
                    return APIResponse(
                        success=False,
                        error="Sorry, the AI could not summarize this question right now. Please try again later or try a different question."
                    )
            else:
                return APIResponse(
                    success=False,
                    error="Anthropic service not available"
                )
        
        elif request.question:
            # Handle direct question input
            title = "Technical Question"
            content = request.question
            
            # Get additional context using Anthropic
            if anthropic_service:
                context_result = await anthropic_service.get_technical_context(request.question)
                content += f"\n\nAdditional Context:\n{context_result}"
        
        # Generate summary using OpenAI
        if openai_service:
            summary_data = await openai_service.summarize_content(title, content, tags)
            
            # Add source URL if available
            if source_url:
                summary_data.source_url = source_url
            
            return APIResponse(
                success=True,
                data=summary_data,
                message="Summary generated successfully"
            )
        else:
            return APIResponse(
                success=False,
                error="OpenAI service not available"
            )
    
    except Exception as e:
        logger.error(f"Error in summarize endpoint: {str(e)}")
        return APIResponse(
            success=False,
            error=f"Internal server error: {str(e)}"
        )


@app.post("/api/chat", response_model=ChatAPIResponse)
async def chat_with_ai(request: ChatRequest):
    """
    Send follow-up questions to the AI
    """
    try:
        if not request.message.strip():
            return ChatAPIResponse(
                success=False,
                error="Message cannot be empty"
            )
        
        if not openai_service:
            return ChatAPIResponse(
                success=False,
                error="OpenAI service not available"
            )
        
        # Generate chat response
        response = await openai_service.chat_response(
            message=request.message,
            context=request.context
        )
        
        return ChatAPIResponse(
            success=True,
            data={
                "message": response,
                "context": f"{request.context or ''}\nUser: {request.message}\nAI: {response}"
            },
            message="Chat response generated successfully"
        )
    
    except Exception as e:
        logger.error(f"Error in chat endpoint: {str(e)}")
        return ChatAPIResponse(
            success=False,
            error=f"Internal server error: {str(e)}"
        )


@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    """Handle HTTP exceptions"""
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "success": False,
            "error": exc.detail
        }
    )


@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    """Handle general exceptions"""
    logger.error(f"Unhandled exception: {str(exc)}")
    return JSONResponse(
        status_code=500,
        content={
            "success": False,
            "error": "Internal server error"
        }
    )


if __name__ == "__main__":
    import uvicorn
    
    host = os.getenv("HOST", "0.0.0.0")
    port = int(os.getenv("PORT", "8000"))
    debug = os.getenv("DEBUG", "False").lower() == "true"
    
    uvicorn.run(
        "app.main:app",
        host=host,
        port=port,
        reload=debug,
        log_level="info"
    ) 